{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:17:00.393165: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-20 15:17:00.393208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-20 15:17:00.394549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, cv2\n",
    "import h5py\n",
    "import tifffile\n",
    "from tqdm import tqdm, trange\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from deepreg.predict import unwrapped_predict, normalize_batched_image\n",
    "from deepreg.model.layer import Warping\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "label_shape = (30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register a video in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiff_path = \"/store1/alicia/jellyfish/concat_cropped_0_11999.tif\"\n",
    "tiff_path = \"/store1/alicia/jellyfish/concat_cropped_12000-29999.tif\"\n",
    "\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/long_first_jelly_again/save/ckpt-626\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/long_first_jelly_redo_DP/save/ckpt-396\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/long_first_jelly_redo_DP_real/save/ckpt-368\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/weights_shifted_2/save/ckpt-385\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_flat-TOOMUCHNORM2/save/ckpt-29\"\n",
    "# checkpoint_path = \"~/store1/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_flat-TOOMUCHNORM2/save/ckpt-29\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/karen/save/ckpt-6\"\n",
    "checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/karen_1_nolearn/save/ckpt-151\"\n",
    "\n",
    "output_video_path = \"/home/brian/data4/brian/PBnJ/out_vids/no_align.mp4\"\n",
    "log_dir = \"/home/brian/data4/brian/PBnJ/out_vids/logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tifffile.imread(tiff_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed img saved\n"
     ]
    }
   ],
   "source": [
    "if 'batched_fixed_image' not in locals():\n",
    "    fixed_image_ARCHIVE = inputs[0] # So we don't have to reload stuff\n",
    "    batched_fixed_image = np.repeat(np.expand_dims(inputs[0], axis=0), batch_size, axis=0).astype(np.float32)\n",
    "    print(\"Fixed img saved\")\n",
    "else:\n",
    "    batched_fixed_image = np.repeat(np.expand_dims(fixed_image_ARCHIVE, axis=0), batch_size, axis=0).astype(np.float32)\n",
    "    print(\"Restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/scripts\")\n",
    "from register import set_GPU, register\n",
    "# set_GPU(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green channel\n",
    "green_channel_folder = \"/home/brian/store1/brian/swiming_videos/GREEN CROPPED VIDEO FOR BRIAN\"\n",
    "green_files = sorted([f for f in os.listdir(green_channel_folder) if int(f.split('-')[0]) >= 12000], key=lambda x: int(x.split('-')[0])) # f.index(\"WARPED\") < 0 and \n",
    "green_offsets = [int(f.split('-')[0]) - 12000 for f in green_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12000-13999.tif - C=0.tif',\n",
       " '14000-15999.tif - C=0.tif',\n",
       " '16000-17999.tif - C=0.tif',\n",
       " '18000-19999.tif - C=0.tif',\n",
       " '20000-21999.tif - C=0.tif',\n",
       " '22000-23999.tif - C=0.tif',\n",
       " '24000-25999.tif - C=0.tif',\n",
       " '26000-27999.tif - C=0.tif',\n",
       " '28000-29999.tif - C=0.tif']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 21:08:42 | WARNING  | Log directory /home/brian/data4/brian/PBnJ/out_vids/logs exists already.\n",
      "2025-03-19 21:08:42 | WARNING  | Using customized configuration. The code might break if the config doesn't match the saved model.\n",
      "Built inputs.\n",
      "Built control points.\n",
      "Concatenated images.\n",
      "{'extract_levels': ListWrapper([0, 1, 2, 3]), 'name': 'local', 'num_channel_initial': 16}\n",
      "Built backbone.\n",
      "Built DDF.\n",
      "Built warping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:11<00:00,  2.62s/it]\n"
     ]
    }
   ],
   "source": [
    "#### FIRST WE'RE GOING TO JUST TRY TO ALIGN TO A SINGLE FRAME\n",
    "## The first batch of good videos was aligned using ckpt-90, going to switch to 626\n",
    "\n",
    "# output_video_path = \"/home/brian/data4/brian/PBnJ/out_vids/first_frame_align.mp4\"\n",
    "output_video_path = \"/home/brian/data4/brian/PBnJ/out_vids/psuedo_col_control_ROIS_nowarp.mp4\"\n",
    "output_h5_path = \"/home/brian/data4/brian/PBnJ/out_vids/first_frame_align.h5\"\n",
    "log_dir = \"/home/brian/data4/brian/PBnJ/out_vids/logs\"\n",
    "\n",
    "config_path = os.path.join(checkpoint_path.split(\"/save\")[0], \"config.yaml\")\n",
    "model = None\n",
    "\n",
    "max_frames = 400\n",
    "# max_frames = 8\n",
    "side_len = 1080\n",
    "red_offset = 12000\n",
    "\n",
    "padding = np.array([[0,0],[0,0],[0,0],[1,1]])\n",
    "\n",
    "batched_fixed_image_pad = np.pad(batched_fixed_image[..., np.newaxis], padding, \"constant\", constant_values=0)\n",
    "\n",
    "# warping = Warping(fixed_image_size=(side_len, side_len, 2), batch_size=batch_size)\n",
    "warping = Warping(fixed_image_size=(side_len, side_len, 3), batch_size=batch_size, interpolation=\"nearest\")\n",
    "\n",
    "for file in green_files:\n",
    "    green_in = tifffile.imread(os.path.join(green_channel_folder, file))\n",
    "    outs = np.zeros_like(green_in)\n",
    "    offset = int(file.split('-')[0])\n",
    "    for frame in trange(offset, max_frames + offset, batch_size):\n",
    "        if frame + batch_size > (max_frames + offset):\n",
    "            frame = (max_frames + offset) - batch_size\n",
    "\n",
    "        batched_moving_image = inputs[(frame - red_offset):(frame-red_offset)+batch_size].astype(np.float32)\n",
    "        batched_moving_image = np.pad(batched_moving_image[..., np.newaxis], padding, \"constant\", constant_values=0)\n",
    "\n",
    "        \n",
    "        ddf_output, pred_fixed_image, model = unwrapped_predict(\n",
    "            batched_fixed_image_pad,\n",
    "            batched_moving_image,\n",
    "            log_dir,\n",
    "            label_shape,\n",
    "            label_shape,\n",
    "            model = model,\n",
    "            model_ckpt_path = checkpoint_path,\n",
    "            model_config_path = config_path,\n",
    "        )\n",
    "\n",
    "        gr_in = np.pad(green_in[(frame - offset):(frame - offset)+batch_size, ..., np.newaxis], padding, \"constant\", constant_values=0).astype(np.float32)\n",
    "        outs[frame - offset:(frame - offset) + batch_size] = warping(inputs=[ddf_output, gr_in]).numpy()[..., 1]\n",
    "\n",
    "    tifffile.imwrite(os.path.join(green_channel_folder, \"WARPED_\" + file), outs)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
